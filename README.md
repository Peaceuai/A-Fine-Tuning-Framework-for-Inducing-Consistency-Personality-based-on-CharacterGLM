# A-Fine-Tuning-Framework-for-Inducing-Consistency-Personality-based-on-CharacterGLM

# Abstract
Large language model–based dialogue systems often struggle to maintain consistent persona traits and resist adversarial prompts. This paper introduces a LoRA-enhanced fine-tuning framework that leverages a custom instruction dataset augmented with adversarial examples generated by ChatGPT-4o. By explicitly encoding both static attributes and dynamic behaviors, the proposed method aligns model outputs with predefined character profiles. Empirical evaluations using two exemplar roles—“Xiao Ming” (introverted student) and “Zhang San” (extroverted programmer)—demonstrate a 35 percentage reduction in out-of-character responses and sustained personality stability under reverse-prompt attacks, as measured by Big Five trait analyses. These results validate the framework’s capacity to produce stable, human-like dialogue agents, offering enhanced user trust and practical utility in applications such as virtual companionship and customer service.

## Requirements

- Colab

## Running the mode of training

Click on the code to execute the program in colab and run it all
![image](https://github.com/user-attachments/assets/4c3858f1-ec30-4474-9e11-29600989efe5)

## Results

 The below picture is about the CNN network
 
![image16](https://github.com/user-attachments/assets/ced89a80-0b36-4ef8-80af-797c23939db1)

 The below picture is about the train line
 
 ![image13](https://github.com/user-attachments/assets/64f10423-7588-4ec1-bf60-ec9a860bfdd9)

 The below picture is about the predict result
 
 ![image15](https://github.com/user-attachments/assets/bc2a4087-d63b-47f2-ac1f-ae05b787e9c7)

## Reference

https://learn.microsoft.com/zh-cn/windows/ai/windows-ml/tutorials/pytorch-data
