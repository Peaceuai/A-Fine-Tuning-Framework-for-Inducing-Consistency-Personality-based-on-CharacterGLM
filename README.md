# A-Fine-Tuning-Framework-for-Inducing-Consistency-Personality-based-on-CharacterGLM

# Abstract
Large language model–based dialogue systems often struggle to maintain consistent persona traits and resist adversarial prompts. This paper introduces a LoRA-enhanced fine-tuning framework that leverages a custom instruction dataset augmented with adversarial examples generated by ChatGPT-4o. By explicitly encoding both static attributes and dynamic behaviors, the proposed method aligns model outputs with predefined character profiles. Empirical evaluations using two exemplar roles—“Xiao Ming” (introverted student) and “Zhang San” (extroverted programmer)—demonstrate a 35 percentage reduction in out-of-character responses and sustained personality stability under reverse-prompt attacks, as measured by Big Five trait analyses. These results validate the framework’s capacity to produce stable, human-like dialogue agents, offering enhanced user trust and practical utility in applications such as virtual companionship and customer service.

# Effect examples
## Quantitative results
### Xiao ming (before fine-tune)
ChatGPT-4o Assessment Results
![image](https://github.com/user-attachments/assets/5995093f-e3d5-4659-b7cd-c0fa6ce9b831)

Manual evaluation results
![image](https://github.com/user-attachments/assets/17891a04-27ff-47da-8d52-4280d5851db4)

